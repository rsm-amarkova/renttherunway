{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4840c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Imports & utilities                            #\n",
    "##################################################\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b58b640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 192544\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Load dataset                                   #\n",
    "##################################################\n",
    "\n",
    "\n",
    "def read_rtr(path):\n",
    "    with gzip.open(path, \"rt\") as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "\n",
    "\n",
    "DATA_PATH = \"renttherunway_final_data.json.gz\"\n",
    "\n",
    "data = list(read_rtr(DATA_PATH))\n",
    "print(\"Total records:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82129700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 154035\n",
      "Valid size: 38509\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Train / validation split                       #\n",
    "##################################################\n",
    "\n",
    "indices = list(range(len(data)))\n",
    "random.shuffle(indices)\n",
    "split = int(0.8 * len(indices))\n",
    "train_idx = set(indices[:split])\n",
    "valid_idx = set(indices[split:])\n",
    "\n",
    "train_data = [data[i] for i in train_idx]\n",
    "valid_data = [data[i] for i in valid_idx]\n",
    "\n",
    "print(\"Train size:\", len(train_data))\n",
    "print(\"Valid size:\", len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e9ff630",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Shared helpers                                 #\n",
    "##################################################\n",
    "\n",
    "\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom > 0:\n",
    "        return numer / denom\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb1cfb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Shared helpers                                 #\n",
    "##################################################\n",
    "\n",
    "\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom > 0:\n",
    "        return numer / denom\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469139e",
   "metadata": {},
   "source": [
    "Rating Prediction  \n",
    "* we must regularize a (destabilizes β updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3fa18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ratings: 153976\n",
      "Valid ratings: 38486\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# 1. Rating prediction  #\n",
    "#########################\n",
    "# r ≈ alpha + beta_u + beta_i  (user/item bias model)\n",
    "\n",
    "\n",
    "# extract ratings from dataset and build rating triples (u, i, r) from data\n",
    "def extract_ratings(dataset):\n",
    "    ratings = []\n",
    "    for d in dataset:\n",
    "        if \"rating\" in d and d[\"rating\"] not in (None, \"\", \"nan\"):\n",
    "            try:\n",
    "                r = float(d[\"rating\"])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            u = d[\"user_id\"]\n",
    "            i = d[\"item_id\"]\n",
    "            ratings.append((u, i, r))\n",
    "    return ratings\n",
    "\n",
    "\n",
    "ratingsTrain = extract_ratings(train_data)\n",
    "ratingsValid = extract_ratings(valid_data)\n",
    "\n",
    "print(\"Train ratings:\", len(ratingsTrain))\n",
    "print(\"Valid ratings:\", len(ratingsValid))\n",
    "\n",
    "# Build per-user / per-item maps\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u, b, r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b, r))\n",
    "    ratingsPerItem[b].append((u, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ea0a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the global average rating\n",
    "def getGlobalAverage(trainRatings):\n",
    "    return sum(r for (_, _, r) in trainRatings) / len(trainRatings)\n",
    "\n",
    "\n",
    "######################\n",
    "# Bias Model Updates #\n",
    "######################\n",
    "\n",
    "\n",
    "# improving alpha update with regularization\n",
    "def alphaUpdate(ratingsTrain, alpha, betaU, betaI, lamb):\n",
    "    newAlpha = 0.0\n",
    "    for u, b, r in ratingsTrain:\n",
    "        newAlpha += r - (betaU.get(u, 0.0) + betaI.get(b, 0.0))\n",
    "    return newAlpha / (len(ratingsTrain) + lamb)\n",
    "\n",
    "\n",
    "def betaUUpdate(ratingsPerUser, alpha, betaU, betaI, lamb):\n",
    "    newBetaU = {}\n",
    "    for u in ratingsPerUser:\n",
    "        num = 0.0\n",
    "        for b, r in ratingsPerUser[u]:\n",
    "            num += r - (alpha + betaI.get(b, 0.0))\n",
    "        newBetaU[u] = num / (lamb + len(ratingsPerUser[u]))\n",
    "    return newBetaU\n",
    "\n",
    "\n",
    "def betaIUpdate(ratingsPerItem, alpha, betaU, betaI, lamb):\n",
    "    newBetaI = {}\n",
    "    for b in ratingsPerItem:\n",
    "        num = 0.0\n",
    "        for u, r in ratingsPerItem[b]:\n",
    "            num += r - (alpha + betaU.get(u, 0.0))\n",
    "        newBetaI[b] = num / (lamb + len(ratingsPerItem[b]))\n",
    "    return newBetaI\n",
    "\n",
    "\n",
    "###################\n",
    "# MSE COMPUTATION #\n",
    "###################\n",
    "\n",
    "\n",
    "def msePlusReg(ratingsTrain, alpha, betaU, betaI, lamb):\n",
    "    mse = 0.0\n",
    "    for u, b, r in ratingsTrain:\n",
    "        pred = alpha + betaU.get(u, 0.0) + betaI.get(b, 0.0)\n",
    "        mse += (r - pred) ** 2\n",
    "    mse /= len(ratingsTrain)\n",
    "\n",
    "    # regularization penalty\n",
    "    reg = sum(b**2 for b in betaU.values()) + sum(b**2 for b in betaI.values())\n",
    "    return mse, mse + lamb * reg\n",
    "\n",
    "\n",
    "def validMSE(ratingsValid, alpha, betaU, betaI):\n",
    "    mse = 0.0\n",
    "    for u, b, r in ratingsValid:\n",
    "        pred = alpha + betaU.get(u, 0.0) + betaI.get(b, 0.0)\n",
    "        mse += (r - pred) ** 2\n",
    "    mse /= len(ratingsValid)\n",
    "    return mse\n",
    "\n",
    "\n",
    "##################\n",
    "# TRAINING LOOP  #\n",
    "##################\n",
    "\n",
    "\n",
    "def train_bias_model(ratingsTrain, ratingsPerUser, ratingsPerItem, lamb=1.0, iters=30):\n",
    "    alpha = getGlobalAverage(ratingsTrain)\n",
    "    betaU = defaultdict(float)\n",
    "    betaI = defaultdict(float)\n",
    "\n",
    "    for _ in range(iters):\n",
    "        alpha = alphaUpdate(ratingsTrain, alpha, betaU, betaI, lamb)\n",
    "\n",
    "        newBetaU = betaUUpdate(ratingsPerUser, alpha, betaU, betaI, lamb)\n",
    "        newBetaI = betaIUpdate(ratingsPerItem, alpha, betaU, betaI, lamb)\n",
    "\n",
    "        betaU.update(newBetaU)  # refine existing estimates, not reset\n",
    "        betaI.update(newBetaI)\n",
    "    return alpha, betaU, betaI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f58498df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ=0.1  Valid MSE=2.4250\n",
      "λ=0.3  Valid MSE=2.2754\n",
      "λ=1  Valid MSE=2.0741\n",
      "λ=3  Valid MSE=1.9540\n",
      "λ=10  Valid MSE=1.9187\n",
      "Rating prediction:\n",
      "  Train MSE: 1.5613052446946623\n",
      "  Valid MSE: 1.9186764817339022\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter search for best lambda\n",
    "# tuning lambda:\n",
    "for lamb in [0.1, 0.3, 1, 3, 10]:\n",
    "    alpha_tmp, bu_tmp, bi_tmp = train_bias_model(\n",
    "        ratingsTrain, ratingsPerUser, ratingsPerItem, lamb=lamb, iters=30\n",
    "    )\n",
    "    print(\n",
    "        f\"λ={lamb}  Valid MSE={validMSE(ratingsValid, alpha_tmp, bu_tmp, bi_tmp):.4f}\"\n",
    "    )\n",
    "\n",
    "# --- Pick λ manually after seeing results ---\n",
    "best_lambda = 10.0\n",
    "\n",
    "alpha, betaU, betaI = train_bias_model(\n",
    "    ratingsTrain, ratingsPerUser, ratingsPerItem, lamb=best_lambda, iters=30\n",
    ")\n",
    "\n",
    "# final metrics\n",
    "train_mse, train_obj = msePlusReg(ratingsTrain, alpha, betaU, betaI, lamb=best_lambda)\n",
    "valid_mse = validMSE(ratingsValid, alpha, betaU, betaI)\n",
    "\n",
    "print(\"Rating prediction:\")\n",
    "print(\"  Train MSE:\", train_mse)\n",
    "print(\"  Valid MSE:\", valid_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f50ee942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITS DEFINITELY OPTIONAL\n",
    "\n",
    "\n",
    "def writePredictionsRating(alpha, betaU, betaI, in_pairs_path, out_path):\n",
    "    with open(out_path, \"w\") as predictions, open(in_pairs_path) as pairs:\n",
    "        for l in pairs:\n",
    "            if l.startswith(\"userID\"):\n",
    "                predictions.write(l)\n",
    "                continue\n",
    "            u, b = l.strip().split(\",\")\n",
    "            pred = alpha + betaU.get(u, 0.0) + betaI.get(b, 0.0)\n",
    "            predictions.write(u + \",\" + b + \",\" + str(pred) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3655a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "\n",
    "def clean_text(s):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = s.lower()\n",
    "    return \"\".join(c for c in s if c not in punctuation)\n",
    "\n",
    "\n",
    "def get_full_text(d):\n",
    "    \"\"\"\n",
    "    Combine review_text and review_summary into a single cleaned string.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    txt = d.get(\"review_text\")\n",
    "    summ = d.get(\"review_summary\")  # may be missing\n",
    "\n",
    "    if txt:\n",
    "        parts.append(clean_text(txt))\n",
    "    if summ:\n",
    "        parts.append(clean_text(summ))\n",
    "\n",
    "    return \" \".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2245249a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rented-for prediction:\n",
      "  Total labeled train examples: 154029\n",
      "  Label counts (top 10): [('wedding', 46303), ('formal affair', 32269), ('party', 28465), ('everyday', 13535), ('other', 12273), ('work', 12035), ('date', 5906), ('vacation', 3242), ('party: cocktail', 1)]\n",
      "  Top 10 labels: ['wedding', 'formal affair', 'party', 'everyday', 'other', 'work', 'date', 'vacation', 'party: cocktail']\n",
      "  Train samples (top-k only): 154029\n",
      "  Valid samples (top-k only): 38505\n",
      "  Unique rented-for labels (train): 9\n",
      "  X_rf_train shape: (154029, 12000)\n",
      "\n",
      "Tuning C:\n",
      "  C=0.5   Train=0.6509  Valid=0.5986\n",
      "  C=1.0   Train=0.6672  Valid=0.5972\n",
      "  C=2.0   Train=0.6835  Valid=0.5927\n",
      "  C=3.0   Train=0.6914  Valid=0.5883\n",
      "  C=5.0   Train=0.7013  Valid=0.5808\n",
      "\n",
      "Best C: 0.5  (valid accuracy = 0.5986)\n",
      "\n",
      "Final model (rented-for prediction):\n",
      "  Train accuracy: 0.6509423550110693\n",
      "  Valid accuracy: 0.5986235553824178\n",
      "\n",
      "Classification report (valid):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         date      0.677     0.260     0.376      1482\n",
      "     everyday      0.535     0.630     0.579      3287\n",
      "formal affair      0.599     0.622     0.610      8139\n",
      "        other      0.539     0.249     0.341      3115\n",
      "        party      0.536     0.544     0.540      7161\n",
      "     vacation      0.671     0.203     0.312       833\n",
      "      wedding      0.642     0.793     0.710     11481\n",
      "         work      0.639     0.525     0.577      3007\n",
      "\n",
      "     accuracy                          0.599     38505\n",
      "    macro avg      0.605     0.478     0.506     38505\n",
      " weighted avg      0.598     0.599     0.584     38505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Task 2 – Category / Event Prediction       #\n",
    "#            (text → rented for)                #\n",
    "##################################################\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# IMPORTANT: use the actual key in the data\n",
    "label_field = \"rented for\"  # key in the JSON\n",
    "top_k = 10  # keep only the top-k most common labels\n",
    "\n",
    "\n",
    "def collect_labels(dataset):\n",
    "    labels = []\n",
    "    for d in dataset:\n",
    "        lab = d.get(label_field)\n",
    "        if lab in (None, \"\", \"nan\"):\n",
    "            continue\n",
    "        labels.append(lab)\n",
    "    return labels\n",
    "\n",
    "\n",
    "# --- 1. Find top-k most common \"rented for\" labels on train set ---\n",
    "all_train_labels = collect_labels(train_data)\n",
    "label_counts = Counter(all_train_labels)\n",
    "\n",
    "print(\"Rented-for prediction:\")\n",
    "print(\"  Total labeled train examples:\", len(all_train_labels))\n",
    "print(\"  Label counts (top 10):\", label_counts.most_common(10))\n",
    "\n",
    "top_k_labels = [lab for lab, _ in label_counts.most_common(top_k)]\n",
    "print(\"  Top\", top_k, \"labels:\", top_k_labels)\n",
    "\n",
    "\n",
    "def extract_texts_and_rented_for(dataset, allowed_labels):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for d in dataset:\n",
    "        lab = d.get(label_field)\n",
    "        if lab in (None, \"\", \"nan\"):\n",
    "            continue\n",
    "        if lab not in allowed_labels:  # drop rare labels\n",
    "            continue\n",
    "        texts.append(get_full_text(d))  # reuse review_text + summary\n",
    "        labels.append(lab)\n",
    "    return texts, np.array(labels)\n",
    "\n",
    "\n",
    "# --- 2. Build train/valid sets restricted to top-k labels ---\n",
    "\n",
    "train_texts_rf, y_rf_train = extract_texts_and_rented_for(train_data, top_k_labels)\n",
    "valid_texts_rf, y_rf_valid = extract_texts_and_rented_for(valid_data, top_k_labels)\n",
    "\n",
    "print(\"  Train samples (top-k only):\", len(train_texts_rf))\n",
    "print(\"  Valid samples (top-k only):\", len(valid_texts_rf))\n",
    "\n",
    "if len(train_texts_rf) == 0:\n",
    "    raise ValueError(\n",
    "        \"No training samples found for 'rented for'. \"\n",
    "        \"Check that label_field matches the key in your data.\"\n",
    "    )\n",
    "\n",
    "print(\"  Unique rented-for labels (train):\", len(np.unique(y_rf_train)))\n",
    "\n",
    "# --- 3. TF-IDF features (separate vectorizer for this task) ---\n",
    "\n",
    "rf_vectorizer = TfidfVectorizer(\n",
    "    max_features=12000,  # a bit richer than 8000\n",
    "    ngram_range=(1, 2),  # unigrams + bigrams\n",
    "    min_df=3,  # drop extremely rare tokens\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "\n",
    "X_rf_train = rf_vectorizer.fit_transform(train_texts_rf)\n",
    "X_rf_valid = rf_vectorizer.transform(valid_texts_rf)\n",
    "\n",
    "print(\"  X_rf_train shape:\", X_rf_train.shape)\n",
    "\n",
    "# --- 4. Encode rented-for labels ---\n",
    "\n",
    "rf_le = LabelEncoder()\n",
    "all_rf_labels = np.concatenate([y_rf_train, y_rf_valid])\n",
    "rf_le.fit(all_rf_labels)\n",
    "\n",
    "y_rf_train_enc = rf_le.transform(y_rf_train)\n",
    "y_rf_valid_enc = rf_le.transform(y_rf_valid)\n",
    "\n",
    "# --- 5. Hyperparameter search for best C ---\n",
    "\n",
    "Cs = [0.5, 1.0, 2.0, 3.0, 5.0]\n",
    "best_C = None\n",
    "best_valid_acc = -1.0\n",
    "best_clf = None\n",
    "\n",
    "print(\"\\nTuning C:\")\n",
    "for C in Cs:\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=300,\n",
    "        solver=\"saga\",\n",
    "        n_jobs=-1,\n",
    "        C=C,\n",
    "        random_state=0,\n",
    "    )\n",
    "    clf.fit(X_rf_train, y_rf_train_enc)\n",
    "    train_pred = clf.predict(X_rf_train)\n",
    "    valid_pred = clf.predict(X_rf_valid)\n",
    "\n",
    "    train_acc = (train_pred == y_rf_train_enc).mean()\n",
    "    valid_acc = (valid_pred == y_rf_valid_enc).mean()\n",
    "\n",
    "    print(f\"  C={C:<4}  Train={train_acc:.4f}  Valid={valid_acc:.4f}\")\n",
    "\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_C = C\n",
    "        best_clf = clf\n",
    "\n",
    "print(f\"\\nBest C: {best_C}  (valid accuracy = {best_valid_acc:.4f})\")\n",
    "\n",
    "# --- 6. Evaluate best model: accuracy + per-class metrics ---\n",
    "\n",
    "rf_train_pred = best_clf.predict(X_rf_train)\n",
    "rf_valid_pred = best_clf.predict(X_rf_valid)\n",
    "\n",
    "rf_train_acc = (rf_train_pred == y_rf_train_enc).mean()\n",
    "rf_valid_acc = (rf_valid_pred == y_rf_valid_enc).mean()\n",
    "\n",
    "print(\"\\nFinal model (rented-for prediction):\")\n",
    "print(\"  Train accuracy:\", rf_train_acc)\n",
    "print(\"  Valid accuracy:\", rf_valid_acc)\n",
    "\n",
    "# Decode predictions back to label names for nice reports\n",
    "y_rf_valid_pred_labels = rf_le.inverse_transform(rf_valid_pred)\n",
    "\n",
    "print(\"\\nClassification report (valid):\")\n",
    "print(classification_report(y_rf_valid, y_rf_valid_pred_labels, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac6ef2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePredictionsCategory(\n",
    "    model, words, wordId, wordSet, label_encoder, in_pairs_path, out_path\n",
    "):\n",
    "    with open(out_path, \"w\") as predictions, open(in_pairs_path) as pairs:\n",
    "        pos = 0\n",
    "        for l in pairs:\n",
    "            if l.startswith(\"userID\"):\n",
    "                predictions.write(l)\n",
    "                continue\n",
    "            u, b = l.strip().split(\",\")\n",
    "            # You would need to look up the review_text for (u, b) here.\n",
    "            # Placeholder: empty text → all zeros except bias.\n",
    "            feat = [0] * len(words) + [1]\n",
    "            pred_label = model.predict(np.array(feat).reshape(1, -1))[0]\n",
    "            pred_cat = label_encoder.inverse_transform([pred_label])[0]\n",
    "            predictions.write(u + \",\" + b + \",\" + str(pred_cat) + \"\\n\")\n",
    "            pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e333398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_for_category(d):\n",
    "    \"\"\"\n",
    "    Build the text used for both category and fit models.\n",
    "    Uses review_text and (optionally) review_summary if it exists.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    txt = d.get(\"review_text\")\n",
    "    summ = d.get(\"review_summary\")  # it's okay if this field doesn't exist\n",
    "\n",
    "    if txt:\n",
    "        parts.append(clean_text(txt))\n",
    "    if summ:\n",
    "        parts.append(clean_text(summ))\n",
    "\n",
    "    return \" \".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0f95695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid fit prediction (h, w, size, body type, bust size, category):\n",
      "  Train samples: 154035\n",
      "  Valid samples: 38509\n",
      "  Fit classes: ['fit' 'large' 'small']\n",
      "  Baseline (always 'fit') valid accuracy: 0.7356\n",
      "\n",
      "Tuning C (maximize accuracy, watch macro F1):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/base-uv/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  C=0.5   Train=0.7372  Valid=0.7344  MacroF1=0.2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/base-uv/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  C=1.0   Train=0.7370  Valid=0.7342  MacroF1=0.2838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/base-uv/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  C=2.0   Train=0.7370  Valid=0.7344  MacroF1=0.2842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/base-uv/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  C=3.0   Train=0.7371  Valid=0.7344  MacroF1=0.2839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/base-uv/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  C=5.0   Train=0.7369  Valid=0.7343  MacroF1=0.2842\n",
      "\n",
      "Best C: 2.0  (valid accuracy = 0.7344, macro F1 = 0.2842)\n",
      "\n",
      "Final hybrid model (→ fit):\n",
      "  Train accuracy: 0.7370208069594573\n",
      "  Valid accuracy: 0.7344257186631696\n",
      "\n",
      "Classification report (valid set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fit      0.736     0.998     0.847     28329\n",
      "       large      0.000     0.000     0.000      4978\n",
      "       small      0.172     0.003     0.006      5202\n",
      "\n",
      "    accuracy                          0.734     38509\n",
      "   macro avg      0.303     0.334     0.284     38509\n",
      "weighted avg      0.565     0.734     0.624     38509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/base-uv/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/base-uv/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/base-uv/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# 5. Task 3 – Fit Prediction (hybrid features)   #\n",
    "#    height + weight + size + bodytype           #\n",
    "#    + bust size + category  → fit               #\n",
    "##################################################\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# --------- helper parsers for numeric fields ---------\n",
    "\n",
    "\n",
    "def parse_height_to_inches(s):\n",
    "    \"\"\"Convert '5\\' 4\\\"' to inches, or return NaN.\"\"\"\n",
    "    if s is None or s in (\"\", \"nan\", \"Missing value\"):\n",
    "        return np.nan\n",
    "    try:\n",
    "        m = re.match(r\"(\\d+)\\s*'\\s*(\\d*)\", s)\n",
    "        if not m:\n",
    "            return np.nan\n",
    "        feet = int(m.group(1))\n",
    "        inches = int(m.group(2) or 0)\n",
    "        return feet * 12 + inches\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def parse_weight_to_lbs(s):\n",
    "    \"\"\"Convert '137lbs' → 137.\"\"\"\n",
    "    if s is None or s in (\"\", \"nan\", \"Missing value\"):\n",
    "        return np.nan\n",
    "    try:\n",
    "        digits = \"\".join(ch for ch in s if ch.isdigit())\n",
    "        return float(digits) if digits else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def safe_float(s):\n",
    "    if s is None or s in (\"\", \"nan\", \"Missing value\"):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# --------- extract hybrid feature set ---------\n",
    "\n",
    "\n",
    "def extract_fit_features_hybrid(dataset):\n",
    "    \"\"\"\n",
    "    Features:\n",
    "      numeric: height (in), weight (lbs), size\n",
    "      categorical: body type, bust size, category\n",
    "    Label:\n",
    "      fit ∈ {fit, small, large}\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    labels = []\n",
    "\n",
    "    for d in dataset:\n",
    "        fit = d.get(\"fit\")\n",
    "        if fit in (None, \"\", \"nan\"):\n",
    "            continue  # need label\n",
    "\n",
    "        height_in = parse_height_to_inches(d.get(\"height\"))\n",
    "        weight_lb = parse_weight_to_lbs(d.get(\"weight\"))\n",
    "        size_num = safe_float(d.get(\"size\"))\n",
    "\n",
    "        body_type = d.get(\"body type\") or \"Unknown\"\n",
    "        bust_size = d.get(\"bust size\") or \"Unknown\"\n",
    "        category = d.get(\"category\") or \"Unknown\"\n",
    "\n",
    "        rows.append([height_in, weight_lb, size_num, body_type, bust_size, category])\n",
    "        labels.append(fit)\n",
    "\n",
    "    return np.array(rows, dtype=object), np.array(labels)\n",
    "\n",
    "\n",
    "# Build train/valid sets\n",
    "X_fit_train, y_fit_train = extract_fit_features_hybrid(train_data)\n",
    "X_fit_valid, y_fit_valid = extract_fit_features_hybrid(valid_data)\n",
    "\n",
    "print(\"Hybrid fit prediction (h, w, size, body type, bust size, category):\")\n",
    "print(\"  Train samples:\", len(X_fit_train))\n",
    "print(\"  Valid samples:\", len(X_fit_valid))\n",
    "\n",
    "# column indices\n",
    "numeric_cols = [0, 1, 2]  # height_in, weight_lb, size_num\n",
    "categorical_cols = [3, 4, 5]  # body_type, bust_size, category\n",
    "\n",
    "# Preprocessor: impute missing + one-hot encode categorical\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), numeric_cols),\n",
    "        (\n",
    "            \"cat\",\n",
    "            Pipeline(\n",
    "                [\n",
    "                    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "                ]\n",
    "            ),\n",
    "            categorical_cols,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Encode fit labels\n",
    "fit_le = LabelEncoder()\n",
    "y_fit_train_enc = fit_le.fit_transform(y_fit_train)\n",
    "y_fit_valid_enc = fit_le.transform(y_fit_valid)\n",
    "\n",
    "print(\"  Fit classes:\", fit_le.classes_)\n",
    "\n",
    "# Baseline: always predict majority class\n",
    "(unique, counts) = np.unique(y_fit_train, return_counts=True)\n",
    "majority_label = unique[np.argmax(counts)]\n",
    "baseline_acc = (y_fit_valid == majority_label).mean()\n",
    "print(f\"  Baseline (always '{majority_label}') valid accuracy: {baseline_acc:.4f}\")\n",
    "\n",
    "# --------- Hyperparameter search for best C (accuracy-focused) ---------\n",
    "\n",
    "Cs = [0.5, 1.0, 2.0, 3.0, 5.0]\n",
    "best_C = None\n",
    "best_valid_acc = -1.0\n",
    "best_model = None\n",
    "best_macro_f1 = None\n",
    "\n",
    "print(\"\\nTuning C (maximize accuracy, watch macro F1):\")\n",
    "for C in Cs:\n",
    "    model = Pipeline(\n",
    "        [\n",
    "            (\"prep\", preprocessor),\n",
    "            (\n",
    "                \"clf\",\n",
    "                LogisticRegression(\n",
    "                    max_iter=400,\n",
    "                    solver=\"lbfgs\",  # good for small/medium feature spaces\n",
    "                    C=C,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=0,\n",
    "                    multi_class=\"auto\",\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.fit(X_fit_train, y_fit_train_enc)\n",
    "    train_pred = model.predict(X_fit_train)\n",
    "    valid_pred = model.predict(X_fit_valid)\n",
    "\n",
    "    train_acc = (train_pred == y_fit_train_enc).mean()\n",
    "    valid_acc = (valid_pred == y_fit_valid_enc).mean()\n",
    "    macro_f1 = f1_score(y_fit_valid_enc, valid_pred, average=\"macro\")\n",
    "\n",
    "    print(\n",
    "        f\"  C={C:<4}  Train={train_acc:.4f}  Valid={valid_acc:.4f}  MacroF1={macro_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_C = C\n",
    "        best_model = model\n",
    "        best_macro_f1 = macro_f1\n",
    "\n",
    "print(\n",
    "    f\"\\nBest C: {best_C}  (valid accuracy = {best_valid_acc:.4f}, macro F1 = {best_macro_f1:.4f})\"\n",
    ")\n",
    "\n",
    "# --------- Final evaluation with best model ---------\n",
    "\n",
    "train_pred = best_model.predict(X_fit_train)\n",
    "valid_pred = best_model.predict(X_fit_valid)\n",
    "\n",
    "train_acc = (train_pred == y_fit_train_enc).mean()\n",
    "valid_acc = (valid_pred == y_fit_valid_enc).mean()\n",
    "\n",
    "print(\"\\nFinal hybrid model (→ fit):\")\n",
    "print(\"  Train accuracy:\", train_acc)\n",
    "print(\"  Valid accuracy:\", valid_acc)\n",
    "\n",
    "print(\"\\nClassification report (valid set):\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_fit_valid_enc, valid_pred, target_names=fit_le.classes_, digits=3\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-uv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
